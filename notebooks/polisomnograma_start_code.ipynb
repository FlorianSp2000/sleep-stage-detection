{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Código básico para un solo paciente\"\n",
    "format: html\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mne\n",
    "import yasa\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Información importante\n",
    "\n",
    "http://dataset.isr.uc.pt/ISRUC_Sleep/Content.pdf\n",
    "\n",
    "Pacientes Data of Subgroup_3. Cada comprimido tiene:\n",
    "* un fichero .rec que es un .edf (RENOMBRARLO)\n",
    "* dos ficheros .txt que son las marcas de los especialistas\n",
    "* dos fichero .xlsx que contienen la misma información (Stage) y más (muy útil si se desea profundizar en porqué se cometen los errores, para descartar épocas de dudosa calidad, etc.).\n",
    "\n",
    "https://sleeptight.isr.uc.pt/?page_id=48\n",
    "\n",
    "El PSG está compuesto por las señales de los siguientes canales:\n",
    "\n",
    "-   EEG (F3, C3, O1, F4, C4 y O2);\n",
    "-   EOG, derecho e izquierdo (ROC y LOC);\n",
    "-   electrocardiograma (ECG);\n",
    "-   tipos de EMG (un m. submentalis -- EMG de la barbilla (X1) -- y dos m. tibialis -- EMG de las piernas);\n",
    "-   Las referencias se colocaron en los lóbulos de las orejas izquierda y derecha (A1, A2).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Canales del polisomnograma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "data_path = Path('../dataset/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from c:\\Machine Learning\\Master Tuebingen\\Semester_3\\HDA\\sleep-stage-detection\\dataset\\1\\1.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 5723999  =      0.000 ... 28619.995 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.3 - 49 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.30\n",
      "- Lower transition bandwidth: 0.30 Hz (-6 dB cutoff frequency: 0.15 Hz)\n",
      "- Upper passband edge: 49.00 Hz\n",
      "- Upper transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 49.50 Hz)\n",
      "- Filter length: 1101 samples (11.010 s)\n",
      "\n",
      "Chan = ['LOC-A2', 'C4-A1', 'X1']\n",
      "Sampling frequency = 100.0 Hz\n",
      "Data shape = (3, 2772000)\n"
     ]
    }
   ],
   "source": [
    "path = data_path / '1/1.edf' #camino al fichero del paciente 1\n",
    "raw = mne.io.read_raw_edf(path, preload=True)\n",
    "#Eliminamos los canales que no queremos, CUIDADO CON QUITAR MUCHOS CANALES PORQUE DESPUÉS NO HAY INTERPRETACIÓN CLÍNICA\n",
    "raw.drop_channels(['X4', 'X5', 'X6', 'DC3', 'X7', 'X8', 'SaO2', 'DC8','ROC-A1', 'F3-A2', 'C3-A2', 'O1-A2', 'F4-A1','O2-A1', 'X2', 'X3' ])\n",
    "#Cambiamos la frecuencia a 100 Hz para reducir el tiempo de cálculo (aprovechamos que no tenemos frecuencias superiores a 50Hz de interés)\n",
    "raw.resample(100)\n",
    "#Filtramos la señal para eliminar la línea basal (f muy bajas producidas por la respiración, movimiento de piernas, etc.) \n",
    "raw.filter(0.3, 49)\n",
    "# Observamos los datos\n",
    "sf = raw.info['sfreq']\n",
    "chan = raw.ch_names\n",
    "print('Chan =', chan)\n",
    "print('Sampling frequency =', sf, 'Hz')\n",
    "#CUIDADO! si se accede directamente a los datos hay que cambiar la escala!\n",
    "data = raw.get_data() * 1e6 #microVolts (porque mne trabaja en V)\n",
    "data = data[:,:-30*30*100] #eliminamos las 30 últimas porque lo indica el artículo de referencia\n",
    "print('Data shape =', data.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etiquetas Fases\n",
    "\n",
    "CODIFICACIÓN DE LAS FASES EN LOS FICHEROS DE ISRUC-SLEEP Dataset (cuidado porque no hay valor 4 (antiguamente se distinguía una fase más))\n",
    "\n",
    "* TXT->STAGE\n",
    "* 0->W\n",
    "* 1->N1\n",
    "* 2->N2\n",
    "* 3->N3\n",
    "* 5->REM\n",
    "\n",
    "The default hypnogram format in YASA is a 1D integer vector where:\n",
    "    \n",
    "* -2 = Unscored\n",
    "* -1 = Artefact / Movement\n",
    "* 0 = Wake\n",
    "* 1 = N1 sleep\n",
    "* 2 = N2 sleep\n",
    "* 3 = N3 sleep\n",
    "* 4 = REM sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargamos las etiquetas del primer médico y eliminamos las 30 por que lo indica el artículo \n",
    "path_lab= data_path / '1/1_1.txt'  #camino a las etiquetas de marcado del clínico 1\n",
    "labels1 = pd.read_csv(path_lab, header = None).squeeze(\"columns\")\n",
    "labels1[labels1==5]=4 #cuidado con la codificación si se quiere utilizar las funciones de YASA... \n",
    "labels1 = labels1[:-30]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Características \n",
    "\n",
    "Generamos un registro por cada 30 segundos de polisomnograma. La función SleepStaging realiza esta tarea pero genera las características que considera el autor de la librería. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtenemos algunas características utilizando la función SleepStaging\n",
    "sls = yasa.SleepStaging(raw, eeg_name ='C4-A1' ,  eog_name='LOC-A2', emg_name='X1')\n",
    "#Eliminamos las 30 últimas épocas\n",
    "sls2 = sls.get_features()[:-30]\n",
    "\n",
    "sls_train = sls2 \n",
    "label_train = labels1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For information of created features:\n",
    "https://raphaelvallat.com/yasa/build/html/generated/yasa.SleepStaging.html\n",
    "\n",
    "Interesting Comment:\n",
    "N1 sleep is the sleep stage with the lowest detection accuracy. This is expected because N1 is also the stage with the lowest human inter-rater agreement. Be very careful for potential misclassification of N1 sleep (e.g. scored as Wake or N2) when inspecting the predicted sleep stages.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo \n",
    "\n",
    "Modelo multiclase sin ajuste de parámetros, ni validación ni generalización. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= sls_train[:]\n",
    "y_train= label_train[:]\n",
    "\n",
    "# Binarize the output\n",
    "y_train = label_binarize(y_train, classes=[0, 1, 2, 3, 4])\n",
    "n_classes = 5\n",
    "# Learn to predict each class against the other\n",
    "classifier = OneVsRestClassifier(\n",
    "     RandomForestClassifier(n_estimators=1000, criterion=\"gini\", random_state=0)\n",
    ")\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "rf = []\n",
    "rf.append(classifier)\n",
    "y_score_train = classifier.predict_proba(X_train)\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "thresholds = dict()\n",
    "roc_auc_train = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], thresholds[i] = roc_curve(y_train[:, i], y_score_train[:, i])\n",
    "    roc_auc_train[i] = auc(fpr[i], tpr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1.0, 1: 1.0, 2: 1.0, 3: 1.0, 4: 1.0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(924, 5)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
